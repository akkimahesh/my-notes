Docker
------
application is working in QA but not working in Prod why?
A) main cause here is changes the configuration in QA and Prod. in QA you we use one type of OS and other production we use another type or another version of OS. this is main cause here. So, when we use Docker images we overcome this issue. because image contains same OS in QA as well as PROD. 

Advantages
----------
in Autoscaling it takes the time to create another VM. but coming to container it takes less time.

docker run nginx VS docker -d run nginx
---------------------------------------
1. when you run first command container will run foreground mode. So, when click CLTR+C container Stopped.
2. when you run second command container will run background mode. So, no need to CLTR+C.
 :> remember pm2 for nodejs. same like this.

docker -d -p 8080:80 nginx
--------------------------
1. here 8080 is the host port number. it means VM port number. and 80 means container port number.
2. when hit <ip_address>:8080 there request come to VM first and VM redirect to container.

To check the container OS
--------------------------
cat /etc/*release

docker exec -it <container_name> bash ---> To login into existing container.

docker inspect <container_id> or <container_name> ----> it prints information about the conatainer in that we able to see container ip address and many more.

Declarative means--> what ever you write you will get it.

docker build -t <url>/<username>/<imagename:latest>

docker tag from:v1 joindevops/from:v1--> rename the image.

RUN vs CMD
----------
RUN instruction runs while image building. Here CMD instruction will not work.
CMD instruction runs while container creation. it keeps container runs infinite times.

LABEL instruction is used identify the particular images by filtering.
command: docker images --filter label=Name=Mahesh

EXPOSE instruction does not perform any operation. It is only for information purpose. It is showing which port number is exposing on the image.

ENV instruction is used give environment variables inside the container.

COPY vs ADD
-----------
COPY instruction is used to copy file/directories from source destination.
ADD instruction is used to copy data from url to destination. if you copy .tar files here it automatically untar in the destination.

CMD vs ENTRYPOINT
-----------------
* These two instructions runs while container creation.
* CMD instruction can be overridden by another command at run time. (like docker run <image_name>:v1 ping yahoo.com)
* ENTRYPOINT instruction can not be overridden. if you do so, it can be append to ENTRYPOINT command. (like this ping yahoo.com ping google.com)
* we can use CMD for arguments and ENTRYPOINT for command.
  example
----------
CMD ["googel.com"] #here CMD is providing options for below ping command.
ENTRYPOINT["ping"]

Security
--------
if anyone login docker container as a root user they can access host storage.
so make sure to keep isolated docker containers. from one container to another container.

So to restricting container from root user by using USER instruction.

write this USER instruction before CMD instruction.

WORKDIR instruction is used changem the path where we run the commands (like cd /tmp) directory related commands not work RUN instructions.
RUN cd /tmp (not work)
WORKDIR /tmp (work)

ARG
----
ARG instruction is like variable at only build time. whatever you assign through command line arguments the value can inside ARG variable.
ARG username
RUN adduser $username
USER $username

how to pass value?
docker build -t arg:v1 --build-arg username=Mahesh 

ARG vs ENV
----------
ARG is for build time.
ENV can store values in the container. 

how you can give ARG values to ENV?
ARG COURSE
ARG TRAINER
ENV COURSE=${COURSE}
ENV TRAINER=${TRAINER}

how to pass values?
docker build -t arg:v1 --build-arg COURSE=DevOps --build-arg Trainer=Mahesh 

* ARG can also be used before FROM instruction.
ARG version
FROM almaalinux:${version} #FROM almaalinux:${version:-8} if users forgot to give value. it takes default value.

Note:- if you give ARG instruction before FROM, so it can not be work after FROM instruction.

ONBUILD instruction tells that if you want to use this image! you need something. It doesn't run while build time.
ONBUILD ADD index.html /usr/share/nginx/html/  #here without index.html file at user he doesn't use this image. 

docker run -d --name mongodb mongodb:v1 #to run the container (create+start)

docker0 --> docker creates own network {host network and docker gateway is not same}

                -----> Docker container
               |        172.168.17.3
               |
Docker host -->|     
172.168.17.1   |
 docker GW     |         
                ------> Docker container
                         172.168.17.2

* Docker containers by default not communicate each other by their names. because,
üëâ Containers on the default bridge network:
‚ùå Do NOT get automatic DNS name resolution
‚ùå Cannot talk using container names
‚úÖ Can talk using IP addresses only (unless you manually link)

üëâ Containers on a user-defined bridge network:
‚úÖ Get automatic DNS
‚úÖ Can talk using container names
‚úÖ Preferred modern approach

docker network ls #list the available networks
docker network create roboshop #create our own bridge network
ifconfig #show network information.
docker run -d --name mongodb --network=roboshop mongodb:1 #we are telling our container to use roboshop network.


High level Architecture [ embedded DNS server ]
------------------------
Container (app2)
     ‚îÇ
     ‚îÇ  DNS query: "who is app1?"
     ‚ñº
127.0.0.11 (Docker embedded DNS)
     ‚îÇ
     ‚îÇ looks into Docker network database
     ‚ñº
Returns: 172.18.0.2
     ‚îÇ
     ‚ñº
app2 connects to app1

if some tell write the Dockerfile
---------------------------------
!. first understand what programming language they write.
2. install necessary software.
3. add the required files.
4. start the image building.

*containers are nothing but our services

docker compose
--------------
* without starting containers one by one we use docker compose to start at singal click.
* docker compose can create network, volumes and attach it to the containers.

sample compose file
-------------------
service:
    mongodb:
      image: mongodb:v1

best practices
--------------
1. use official images
2. reduce image size by using bare minimum OS like alpine, disto, core os, etc.
3. use multi stage builds
4. use docker volumes to persist the data
5. use custom network to isolate containers from other projects

* multi stage builds 
--------------------
multi stage builds are used for java projects. because run java application we need artifact right. for generating that use maven after generated we don't want maven. and then run that artifact on JRE. for these conditions we multi stages. if we don't follow multi staging abiously images size will be high.



















 